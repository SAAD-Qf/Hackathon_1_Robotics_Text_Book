{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/docs/intro","label":"Tutorial Intro","docId":"intro","unlisted":false},{"type":"category","label":"physical-ai-book","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/physical-ai-book/intro","label":"Introduction","docId":"physical-ai-book/intro","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/humanoid","label":"Humanoid","docId":"physical-ai-book/humanoid","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/sensors","label":"Sensors","docId":"physical-ai-book/sensors","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/actuators","label":"Actuators","docId":"physical-ai-book/actuators","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/locomotion","label":"Locomotion","docId":"physical-ai-book/locomotion","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/vision","label":"Vision","docId":"physical-ai-book/vision","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/perception","label":"Perception","docId":"physical-ai-book/perception","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/planning","label":"Planning","docId":"physical-ai-book/planning","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/control","label":"Control","docId":"physical-ai-book/control","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/simulation","label":"Simulation","docId":"physical-ai-book/simulation","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/ros2","label":"ROS 2","docId":"physical-ai-book/ros2","unlisted":false},{"type":"link","href":"/docs/physical-ai-book/project","label":"Project","docId":"physical-ai-book/project","unlisted":false}]}]},"docs":{"intro":{"id":"intro","title":"Tutorial Intro","description":"Let's discover Docusaurus in less than 5 minutes.","sidebar":"tutorialSidebar"},"physical-ai-book/actuators":{"id":"physical-ai-book/actuators","title":"Motors & Actuators","description":"Actuators are the muscles of robots. They convert electrical signals from controllers into mechanical movement, enabling robots to walk, grasp, or manipulate objects.","sidebar":"tutorialSidebar"},"physical-ai-book/control":{"id":"physical-ai-book/control","title":"Control Systems","description":"Control Systems manage how a humanoid robot executes movements accurately, stably, and safely. They bridge the gap between planned motion and real-world execution.","sidebar":"tutorialSidebar"},"physical-ai-book/humanoid":{"id":"physical-ai-book/humanoid","title":"Humanoid Robotics","description":"Welcome to the world of Humanoid Robotics! In this chapter, we explore robots that mimic human form and behavior, and learn how AI enables them to perceive, plan, and act in real-world environments.","sidebar":"tutorialSidebar"},"physical-ai-book/intro":{"id":"physical-ai-book/intro","title":"Introduction to Physical AI","description":"Welcome, future architects of physical intelligence! This chapter introduces you to Physical AI and explores how AI moves beyond digital environments to interact with the real, physical world.","sidebar":"tutorialSidebar"},"physical-ai-book/locomotion":{"id":"physical-ai-book/locomotion","title":"Locomotion & Walking","description":"Locomotion is how a humanoid robot moves from one place to another. It combines actuation, balance, sensors, and control algorithms to achieve walking, running, or dynamic movements.","sidebar":"tutorialSidebar"},"physical-ai-book/perception":{"id":"physical-ai-book/perception","title":"Perception Systems","description":"Perception Systems allow humanoid robots to understand their environment through sensors and AI. They process visual, depth, and motion data to make intelligent decisions.","sidebar":"tutorialSidebar"},"physical-ai-book/planning":{"id":"physical-ai-book/planning","title":"Motion Planning","description":"Motion Planning is the process of determining how a humanoid robot moves from one position to another while avoiding obstacles and respecting its physical constraints.","sidebar":"tutorialSidebar"},"physical-ai-book/project":{"id":"physical-ai-book/project","title":"Project Implementation","description":"In this final chapter, you will combine all modules to implement a fully functional autonomous humanoid robot. This project integrates Physical AI principles, ROS 2, Gazebo/Unity simulation, NVIDIA Isaac AI, motion planning, control systems, perception, and VLA (Vision-Language-Action).","sidebar":"tutorialSidebar"},"physical-ai-book/ros2":{"id":"physical-ai-book/ros2","title":"ROS 2 Framework","description":"In this chapter, we dive into the Robot Operating System 2 (ROS 2) framework. ROS 2 is the backbone of humanoid robotics, providing a distributed, reliable, and modular architecture for controlling robots.","sidebar":"tutorialSidebar"},"physical-ai-book/sensors":{"id":"physical-ai-book/sensors","title":"Sensors in Robotics","description":"Sensors are the eyes, ears, and skin of robots. They allow humanoid robots to perceive the environment, understand their own state, and make decisions based on real-world data.","sidebar":"tutorialSidebar"},"physical-ai-book/simulation":{"id":"physical-ai-book/simulation","title":"Robotics Simulation","description":"In this chapter, we explore robotics simulation, a crucial step before deploying humanoid robots in real environments. Simulation helps test, validate, and debug your ROS 2 nodes safely.","sidebar":"tutorialSidebar"},"physical-ai-book/vision":{"id":"physical-ai-book/vision","title":"Vision & Robot Perception","description":"Robot vision allows humanoids to see and interpret their environment. It combines cameras, sensors, and AI algorithms to enable tasks like object detection, navigation, and interaction.","sidebar":"tutorialSidebar"}}}}